{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### MLM Logic"
      ],
      "metadata": {
        "id": "ljs97mwLwjQK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, we will train for Masked Language Modelling."
      ],
      "metadata": {
        "id": "P2y_nmbwwmVt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, import everything."
      ],
      "metadata": {
        "id": "46YHtwqtwu06"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KmNRoDeAwab6",
        "outputId": "38c8c255-1447-4fd3-af08-a89f67b96977"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "from transformers import BertTokenizer, BertForMaskedLM\n",
        "import torch\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertForMaskedLM.from_pretrained('bert-base-uncased')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Example Text"
      ],
      "metadata": {
        "id": "30LJMFBKjFYV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# text = (\"After Abrahm Lincoln won the November 1860 Presidential [MASK] on an \"\n",
        "#         \"anti-slavery platform, an initial seven slave states declared their \"\n",
        "#         \"secession from the country to form the Confederacy. War broke out in \"\n",
        "#         \"1861 when sessionist forces [MASK] Fort Sumter in South \"\n",
        "#         \"Carolina, just over a month after Lincoln's inauguration\")\n",
        "text = (\"After Abrahm Lincoln won the November 1860 Presidential election on an \"\n",
        "        \"anti-slavery platform, an initial seven slave states declared their \"\n",
        "        \"secession from the country to form the Confederacy. War broke out in \"\n",
        "        \"1861 when sessionist forces attacked Fort Sumter in South \"\n",
        "        \"Carolina, just over a month after Lincoln's inauguration\")"
      ],
      "metadata": {
        "id": "VkfGMJbixNkG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, we will tokenize our text."
      ],
      "metadata": {
        "id": "bYIDPfb1yflJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# inputs = tokenizer(text, return_tensors='pt', max_length=512, truncation=True, padding='max_length')\n",
        "# using pyTorch so we want to return tensors\n",
        "inputs = tokenizer(text, return_tensors='pt')\n",
        "inputs.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5XYJM0UxNc6",
        "outputId": "0186d069-6cde-47ca-9647-dc8c58ae985f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Special Tokens\n",
        "\n",
        "103 = MASK token\n",
        "\n",
        "101 = special token\n",
        "\n",
        "Everything else is actual token text."
      ],
      "metadata": {
        "id": "GaWWtFxLy_Wg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs.input_ids"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kR9OUKW7xNaU",
        "outputId": "695f4800-1121-4389-f705-52aec357fd9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  101,  2044, 11113, 10404,  2213,  5367,  2180,  1996,  2281,  7313,\n",
              "          4883,  1031,  2602,  2006,  2019,  3424,  1011,  8864,  4132,  1010,\n",
              "          2019,  3988,  2698,  6658,  2163,  4161,  2037, 22965,  2013,  1996,\n",
              "          2406,  2000,  2433,  1996, 18179,  1012,  2162,  3631,  2041,  1999,\n",
              "          6863,  2043,  5219,  2923,  2749,  4457,  3481,  7680,  3334,  1999,\n",
              "          2148,  3792,  1010,  2074,  2058,  1037,  3204,  2044,  5367,  1005,\n",
              "          1055, 17331,   102]])"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create target labels under the tensor name 'labels'\n",
        "It is a copy of input_id tensor so just clone it."
      ],
      "metadata": {
        "id": "3TTrPw27zsYH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "create our labels tensor by cloning the input_ids tensor.\n",
        "\n"
      ],
      "metadata": {
        "id": "0LQC5y220RKb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs['labels'] = inputs.input_ids.detach().clone()"
      ],
      "metadata": {
        "id": "qrMR7_7uxNW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hMBtR4INxNT2",
        "outputId": "3b50b145-c1e3-4297-a0e5-755b485075aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[  101,  2044, 11113, 10404,  2213,  5367,  2180,  1996,  2281,  7313,\n",
              "          4883,  1031,  2602,  2006,  2019,  3424,  1011,  8864,  4132,  1010,\n",
              "          2019,  3988,  2698,  6658,  2163,  4161,  2037, 22965,  2013,  1996,\n",
              "          2406,  2000,  2433,  1996, 18179,  1012,  2162,  3631,  2041,  1999,\n",
              "          6863,  2043,  5219,  2923,  2749,  4457,  3481,  7680,  3334,  1999,\n",
              "          2148,  3792,  1010,  2074,  2058,  1037,  3204,  2044,  5367,  1005,\n",
              "          1055, 17331,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]), 'labels': tensor([[  101,  2044, 11113, 10404,  2213,  5367,  2180,  1996,  2281,  7313,\n",
              "          4883,  1031,  2602,  2006,  2019,  3424,  1011,  8864,  4132,  1010,\n",
              "          2019,  3988,  2698,  6658,  2163,  4161,  2037, 22965,  2013,  1996,\n",
              "          2406,  2000,  2433,  1996, 18179,  1012,  2162,  3631,  2041,  1999,\n",
              "          6863,  2043,  5219,  2923,  2749,  4457,  3481,  7680,  3334,  1999,\n",
              "          2148,  3792,  1010,  2074,  2058,  1037,  3204,  2044,  5367,  1005,\n",
              "          1055, 17331,   102]])}"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we mask a random number of input ids or tokens within the input_ids tensor but not the labels tensor"
      ],
      "metadata": {
        "id": "qpMduTm1z-1x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we mask tokens in the input_ids tensor, using the 15% probability we used before - and the not a CLS or SEP token condition. This time, because we have padding tokens we also need to exclude PAD tokens (0 input ids)."
      ],
      "metadata": {
        "id": "omvjUU4x0V0-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create random array of floats with equal dimensions to input_ids tensor\n",
        "rand = torch.rand(inputs.input_ids.shape)\n",
        "rand.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5NdXNf0zxNRu",
        "outputId": "f849b805-2991-4f0e-c0a9-e4e981ddd4b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 63])"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rand"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9e_9VjYc0ofp",
        "outputId": "1de147bb-c251-4a6e-9cc2-8fb20744323e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.5781, 0.3307, 0.1340, 0.4611, 0.3069, 0.1520, 0.1894, 0.1903, 0.4399,\n",
              "         0.6487, 0.2077, 0.2646, 0.1158, 0.1014, 0.1104, 0.7378, 0.2717, 0.3029,\n",
              "         0.5183, 0.5930, 0.5438, 0.7892, 0.3562, 0.6088, 0.4990, 0.6191, 0.6214,\n",
              "         0.1239, 0.3377, 0.5458, 0.4842, 0.8023, 0.9957, 0.0618, 0.8546, 0.5215,\n",
              "         0.6935, 0.7516, 0.9613, 0.8956, 0.0335, 0.0840, 0.4051, 0.1205, 0.9481,\n",
              "         0.3516, 0.0479, 0.8222, 0.5770, 0.6068, 0.0263, 0.5486, 0.8625, 0.4247,\n",
              "         0.9496, 0.8863, 0.7352, 0.3732, 0.3446, 0.4884, 0.2773, 0.9050, 0.2130]])"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create mask array\n",
        "mask_arr = (rand < 0.15) * (inputs.input_ids != 101) * (inputs.input_ids != 102) * (inputs.input_ids != 0)"
      ],
      "metadata": {
        "id": "zAGvhqf30ylP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mask_arr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rO3DUAzx1Hgt",
        "outputId": "4669b47c-f5c7-4af8-e530-6e21e8470076"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[False, False,  True, False, False, False, False, False, False, False,\n",
              "         False, False,  True,  True,  True, False, False, False, False, False,\n",
              "         False, False, False, False, False, False, False,  True, False, False,\n",
              "         False, False, False,  True, False, False, False, False, False, False,\n",
              "          True,  True, False,  True, False, False,  True, False, False, False,\n",
              "          True, False, False, False, False, False, False, False, False, False,\n",
              "         False, False, False]])"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gives boolean array.\n",
        "Where TRUE are the masked tokens.\n",
        "\n",
        "But first & last token i.e., special tokens are not to be Masked.\n",
        "\n",
        "We don't want to mask our Separator or Classifier token (any special tokens)"
      ],
      "metadata": {
        "id": "x7jeFaBn1OJI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extra logic to avoid Masking special tokens."
      ],
      "metadata": {
        "id": "CDyJwdc41auc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 101 = Classifier token\n",
        "# 102 = Separator token\n",
        "# (inputs.input_ids != 101) * (inputs.input_ids != 102) * (inputs.input_ids != 0)"
      ],
      "metadata": {
        "id": "6X2D2mOR0yjn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mask_arr[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VEvn_9Wu0yh3",
        "outputId": "49bbf4f7-6890-4452-9091-e7fcf3edac73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([False, False,  True, False, False, False, False, False, False, False,\n",
              "        False, False,  True,  True,  True, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False,  True, False, False,\n",
              "        False, False, False,  True, False, False, False, False, False, False,\n",
              "         True,  True, False,  True, False, False,  True, False, False, False,\n",
              "         True, False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False])"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# gives us a vector of indices where we have True values\n",
        "mask_arr[0].nonzero()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AhjgVFDM0yfh",
        "outputId": "c005b3dd-7e35-4ffc-cb40-07f400ef38e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 2],\n",
              "        [12],\n",
              "        [13],\n",
              "        [14],\n",
              "        [27],\n",
              "        [33],\n",
              "        [40],\n",
              "        [41],\n",
              "        [43],\n",
              "        [46],\n",
              "        [50]])"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# convert vector to list\n",
        "mask_arr[0].nonzero().tolist()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kIpOden_0ycV",
        "outputId": "dc720826-0029-47ee-8c5b-83f8bf6cff9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[2], [12], [13], [14], [27], [33], [40], [41], [43], [46], [50]]"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we have list within list therefore flatten\n",
        "selection = torch.flatten(mask_arr[0].nonzero()).tolist()"
      ],
      "metadata": {
        "id": "Bf4ssQs40yaQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "selection"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x8FUnN2r0yW8",
        "outputId": "ef09e81c-67c4-45c2-c4a2-3296837bfa80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2, 12, 13, 14, 27, 33, 40, 41, 43, 46, 50]"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 103 = MASK token\n",
        "# to select first part of inputs.input_ids tensor so 0th index\n",
        "inputs.input_ids[0, selection] = 103"
      ],
      "metadata": {
        "id": "wS7HzdTP0yT0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have MASK tokens in 15% positions.\n",
        "\n",
        "We can see the values 103 have been assigned in the same positions as we found True values in the mask_arr tensor."
      ],
      "metadata": {
        "id": "bEAyGqkP3WL9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs.input_ids"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dzVDZqOm3S4i",
        "outputId": "72586f16-0aa4-49e4-ad38-1d58493e90ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  101,  2044,   103, 10404,  2213,  5367,  2180,  1996,  2281,  7313,\n",
              "          4883,  1031,   103,   103,   103,  3424,  1011,  8864,  4132,  1010,\n",
              "          2019,  3988,  2698,  6658,  2163,  4161,  2037,   103,  2013,  1996,\n",
              "          2406,  2000,  2433,   103, 18179,  1012,  2162,  3631,  2041,  1999,\n",
              "           103,   103,  5219,   103,  2749,  4457,   103,  7680,  3334,  1999,\n",
              "           103,  3792,  1010,  2074,  2058,  1037,  3204,  2044,  5367,  1005,\n",
              "          1055, 17331,   102]])"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can pass this on to the model which will calculate our Loss & Logits (actual token at the place of MASK token)"
      ],
      "metadata": {
        "id": "5fAAsd8Q331I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = model (**inputs)"
      ],
      "metadata": {
        "id": "mj444uZE3S2c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Outputs has 2 tensors loss & logits"
      ],
      "metadata": {
        "id": "YG_L16VAlg_b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "outputs.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1eV9Z7St3S0q",
        "outputId": "5dbc01e2-d61d-4d36-c64a-e95bd718934a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "odict_keys(['loss', 'logits'])"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs.loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t4438iTS3Sy1",
        "outputId": "bcf62a47-a20a-4c94-a119-2019f465ef96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.6917, grad_fn=<NllLossBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    }
  ]
}